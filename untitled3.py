# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1t5BesVDjtw4a1e1tLMrBvYx67H-4gqnV
"""

import pandas as pd 
import numpy as np 
import matplotlib.pyplot as plt

gasMC = pd.read_csv('gastext.csv', encoding = "ISO-8859-1")
gasMC

gasMC['Target'].value_counts()

gasMC=gasMC.sort_values(by=['Target'],ignore_index=True)
gasMC

#Check Dimensions before pre-processing - 1037
def dim():
  dimensions=len(set(gasMC['Comment'].str.split().explode().values))
  print(f'{dimensions} dimension in the potential DFM.')
dim()

freqMC=pd.Series(' '.join(gasMC['Comment']).split()).value_counts()[:20] 
freqMC

#Remove Punctuation 
gasMC['Comment']=gasMC['Comment'].str.replace(r'[^\w\s]+','')

#Make everything lower case 
gasMC['Comment']=gasMC['Comment'].str.lower()
gasMC

#Stopwords
import nltk 
nltk.download('stopwords')
from nltk.corpus import stopwords
stop=stopwords.words('english')
gasMC['Comment']=gasMC['Comment'].apply(lambda x: " ".join(x for x in x.split() if x not in stop))

freqMC=pd.Series(' '.join(gasMC['Comment']).split()).value_counts()[:50] 
freqMC

#Further removal of unnecessary words 
stop +=['use','get','always','cant','double','anything','many','enough','stop','access','1000','take','buy']
gasMC['Comment']=gasMC['Comment'].apply(lambda x: " ".join(x for x in x.split() if x not in stop))

freqMC=pd.Series(' '.join(gasMC['Comment']).split()).value_counts()[:20] 
freqMC

#Stemming
from nltk.stem import PorterStemmer
st=PorterStemmer()
gasMC['Comment']=gasMC['Comment'].apply(
    lambda x: " ".join([st.stem(word) for word in x.split()])
)

#Final Dimension Check after all necessary pre-processing - 578 
dim()

freqMC=pd.Series(' '.join(gasMC['Comment']).split()).value_counts()[:20] 
freqMC

#Generate WordCloud
from wordcloud import WordCloud
comment_wordsMC = str(' '.join(gasMC['Comment']).split()) 

import string 
comment_wordsMC = comment_wordsMC.translate(str.maketrans('','',string.punctuation))
wordcloud=WordCloud(background_color='white', 
                          max_words=200, 
                          width=1000,height=1000, 
                         ).generate(comment_wordsMC)
plt.figure(figsize=(8,8))
plt.clf()
plt.imshow(wordcloud)
plt.axis('off')
plt.show()

#Generate DFM 
completeMC = gasMC.Comment
corpusMC=[doc.split() for doc in completeMC]
corpusMC

#Generate Corpus
import gensim
from gensim import corpora, models 

dictionaryMC=corpora.Dictionary(corpusMC)

dictionaryMC.filter_extremes(no_below=2, no_above=0.75)

DFM_MC=[dictionaryMC.doc2bow(doc) for doc in corpusMC]
print(DFM_MC)

len(DFM_MC)

print(dictionaryMC.token2id)

from gensim.similarities import MatrixSimilarity 
similMC=MatrixSimilarity(DFM_MC, num_features=len(dictionaryMC)) 
distance=1 - similMC[DFM_MC]

from scipy.cluster import hierarchy
Z_MC=hierarchy.linkage(distance,'single')
plt.figure(figsize=(20,10))
dn_MC=hierarchy.dendrogram(Z_MC,orientation='right',
                        leaf_font_size='11',
                        labels=gasMC.index)

text_simMC=pd.DataFrame(similMC[DFM_MC])
text_simMC[76].sort_values(ascending=False)

text_simMC

from gensim.models import Word2Vec
modelMC=Word2Vec(corpusMC,
               min_count=20,
               size=40,
               workers=3,
               window=3,
               sg=1)

#Similarity for "Price"
modelMC.wv.most_similar('price',topn=5)

#Similarity for "Servic"
modelMC.wv.most_similar('servic',topn=5)

#Topic Modeling with 3 Topics
from gensim.models.ldaseqmodel import ldamodel

n_topics=3
ldamodelMC=models.LdaModel(DFM_MC,
                         num_topics=n_topics,
                         id2word=dictionaryMC,
                         passes=40)
print(ldamodelMC.print_topics(num_topics=n_topics,
                            num_words=10))

!pip install pyLDAvis
import pyLDAvis
pyLDAvis.enable_notebook()

#Generate Intertopic Distance Map 
import pyLDAvis.gensim_models
visMC=pyLDAvis.gensim_models.prepare(ldamodelMC,
                                   DFM_MC,
                                   dictionaryMC)
visMC

#Preparing Tree Model 1
treeMC1=gasMC.drop(labels=['Cust_ID','Comment'], axis=1)
y=treeMC1['Target']

X_MC=treeMC1=treeMC1.drop(labels='Target', axis=1)

from sklearn.model_selection import train_test_split

X_trainMC, X_valMC, y_trainMC, y_valMC =train_test_split(X_MC,y,test_size=0.3,random_state=0)

from sklearn import tree
from sklearn.tree import export_text 

dtreeMC = tree.DecisionTreeClassifier(max_depth=4, min_samples_split=30)
dtreeMC = dtreeMC.fit(X_trainMC,y_trainMC)

#Tree plot for Tree Model 1
from matplotlib import pyplot as plt 
plt.figure(figsize=[25,20])
tree.plot_tree(dtreeMC,
               feature_names=list(X_trainMC.columns.values),
               class_names=True,
               filled=True)
plt.show()

#Validation Score for Tree Model 1
dtreeMC.score(X_valMC,y_valMC)

#Preparing Tree Model 2 
treeMC2=gasMC.drop(labels=['Comment'], axis=1)

tree_MC2=treeMC2.drop(labels=['Cust_ID', 'Target'], axis=1)

tree_MC2

#TFIDF
tfidfMC=models.TfidfModel(DFM_MC)
DFM_tfidfMC=tfidfMC[DFM_MC]

#SVD
n_SVD=6
SVD_modelMC=models.LsiModel(DFM_tfidfMC,
                          id2word=dictionaryMC,
                          num_topics=n_SVD)
SVD_MC=SVD_modelMC[DFM_tfidfMC]

svd_arrayMC=gensim.matutils.corpus2csc(SVD_MC).T.toarray()
svd_dfMC=pd.DataFrame(svd_arrayMC)
svd_dfMC

X_MC2=pd.concat([svd_dfMC,tree_MC2],axis=1)

X_trainMC2, X_valMC2, y_trainMC2, y_valMC2 = train_test_split(X_MC2,y, test_size=0.3,random_state=0)

from sklearn import tree
from sklearn.tree import export_text 

dtreeMC2 = tree.DecisionTreeClassifier(max_depth=4, min_samples_split=30)
dtreeMC2 = dtreeMC2.fit(X_trainMC2,y_trainMC2)

#Tree Plot for Tree Model 2
from matplotlib import pyplot as plt
plt.figure(figsize=[25,20])
tree.plot_tree(dtreeMC2,
               feature_names=list(X_trainMC2.columns.values),
               class_names=True,
               filled=True)
plt.show()

#Validation score for Tree Model 2
dtreeMC2.score(X_valMC2, y_valMC2)